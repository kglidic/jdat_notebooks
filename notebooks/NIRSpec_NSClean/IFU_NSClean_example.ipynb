{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27997993-b40d-4857-94c1-2d88989b4d94",
   "metadata": {},
   "source": [
    "# Cleaning Residual 1/f Noise in NIRSpec IFU Products with NSClean \n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "**Latest update**: Feburary 29, 2024.\n",
    "\n",
    "## Notebook Goal\n",
    "\n",
    "The goal of this notebook is to generate cleaned IFU (*_rate.fits*) files by removing residual 1/f noise. These cleaned files will be used as input for the level 3 (`Spec3Pipeline`) pipeline.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* 1. [Introduction](#introduction)\n",
    "* 2. [Import Library](#imports)\n",
    "* 3. [Convenience Functions](#functions)\n",
    "* 4. [Download the Data](#data)\n",
    "* 5. [Running `Spec2Pipeline` without NSClean (Original Data)](#nsclean_skipped)\n",
    "* 6. [Clean up 1/f Noise with NSClean (Default Pipeline Mask)](#nsclean_default)\n",
    "    * 6.1 [Verify the Mask (Default Pipeline Mask)](#verify_default_mask)\n",
    "    * 6.2 [Comparing Original vs. Cleaned Data (Default Pipeline Mask)](#nsclean_default_compare)\n",
    "* 7. [Clean up 1/f Noise with NSClean (Alternate Mask)](#nsclean_alternate)\n",
    "    * 7.1 [Verify the Mask (Alternate Mask)](#verify_alternate_mask)\n",
    "    * 7.2 [Comparing Original vs. Cleaned Data (Alternate Mask)](#nsclean_alternate_compare)\n",
    "* 8. [Clean up 1/f Noise with NSClean (Hand-Modified Mask)](#nsclean_modified)\n",
    "    * 8.1 [Verify the Mask (Hand-Modified Mask)](#verify_modified_mask)\n",
    "    * 8.2 [Comparing Original vs. Cleaned Data (Hand-Modified Mask)](#nsclean_modified_compare)\n",
    "* 9. [Conclusion](#conclusion)\n",
    "\n",
    "## 1. Introduction <a name=\"introduction\"></a>\n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "The JWST NIRSpec instrument has a number of features and characteristics that observers should be aware of when planning observations and interpreting data. One notable feature seen in NIRSpec pipeline products is negative and/or surplus flux in the extracted 1-D spectrum, typically with an irregular wavelength-dependent undulation. The cause of this artifact is correlated noise, known as [1/f noise](https://jwst-docs.stsci.edu/jwst-near-infrared-spectrograph/nirspec-instrument-features-and-caveats#NIRSpecInstrumentFeaturesandCaveats-1/fnoise), from low-level detector thermal instabilities, seen as vertical banding in 2-D count rate images, particularly in exposures of the NRS2 detector. While the IRS2 readout mode reduces this effect, it is not completely eliminated.\n",
    "\n",
    "To address this issue, the JWST Science Calibration Pipeline has integrated an external package developed by Bernard Rauscher, known as [NSClean](https://webb.nasa.gov/content/forScientists/publications.html#NSClean), within the `Spec2Pipeline` under [NSCleanStep](https://jwst-pipeline.readthedocs.io/en/latest/jwst/nsclean/main.html). This algorithm uses dark areas of the detector to fit a background model to the data in Fourier space. It requires an input mask to identify all dark areas of the detector. The more thorough and complete this mask is, the better the background fit.\n",
    "\n",
    "In this notebook, we will use the NSClean algorithm integrated into the pipeline, utilizing a mask generated on-the-fly with default parameters to remove 1/f noise. In some cases, this mask may not be complete enough/too restrictive for the best possible noise removal. To address this, we demonstrate how one can manually modify the default mask, as well as how to create an alternative mask by adjusting the [NSCleanStep parameters](https://jwst-pipeline.readthedocs.io/en/latest/jwst/nsclean/arguments.html). If needed, see the [NSClean documentation](https://iopscience.iop.org/article/10.1088/1538-3873/ad1b36/pdf) for some suggestions on manually creating a custom mask.\n",
    "\n",
    "This notebook utilizes IFU observation of quasar XID2028 with grating/filter G140H/F100LP as part of [JWST Early Release Science program ERS-1335](https://www.stsci.edu/jwst/science-execution/approved-programs/dd-ers/program-1335) observation 4, as an example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634f12e2-2811-4e05-a883-fd7d56acb230",
   "metadata": {},
   "source": [
    "## 2. Import Library <a name=\"imports\"></a>\n",
    "<hr style=\"border:1px solid black\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44ae42f-8af5-407f-8ad3-248cb36b451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ General Imports ------\n",
    "import numpy as np\n",
    "import time as tt\n",
    "import logging\n",
    "import warnings\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# ------ JWST Calibration Pipeline Imports ------\n",
    "import jwst\n",
    "from stpipe import crds_client\n",
    "from jwst.pipeline.calwebb_spec2 import Spec2Pipeline\n",
    "\n",
    "# ------ Plotting/Stats Imports ------\n",
    "from matplotlib import pyplot as plt\n",
    "from astropy.stats import sigma_clip\n",
    "from astropy.io import fits\n",
    "\n",
    "# Hide all log and warning messages.\n",
    "logging.disable(logging.ERROR)\n",
    "warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "\n",
    "# Print current JWST versions and CRDS context.\n",
    "print(f\"JWST calibration pipeline version: {jwst.__version__}\")\n",
    "print(f\"Current CRDS context: {crds_client.get_context_used('jwst')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52a3be7-5a74-4420-8221-c4b3f8b2324c",
   "metadata": {},
   "source": [
    "## 3. Convenience Functions <a name=\"functions\"></a>\n",
    "<hr style=\"border:1px solid black\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f3ba0-f15f-4c24-bdbc-aaf77837f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jwst_file(name, mast_api_token=None, save_directory=\".\", redownload=False):\n",
    "    \"\"\"\n",
    "    Retrieve a JWST data file from MAST archive and save it to a specified directory.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    name: str\n",
    "        File name.\n",
    "    mast_api_token: str\n",
    "        MAST authorization token. Get your MAST Token Here: https://auth.mast.stsci.edu/token.\n",
    "    save_directory: str\n",
    "        Save directory path.\n",
    "    redownload: bool\n",
    "        Redownload the data even if it exsits already?\n",
    "    \"\"\"\n",
    "    mast_url = \"https://mast.stsci.edu/api/v0.1/Download/file\"\n",
    "    params = dict(uri=f\"mast:JWST/product/{name}\")\n",
    "\n",
    "    if mast_api_token:\n",
    "        headers = dict(Authorization=f\"token {mast_api_token}\")\n",
    "    else:\n",
    "        headers = {}\n",
    "\n",
    "    file_path = os.path.join(save_directory, name)\n",
    "\n",
    "    # Check if the file already exists in the save directory.\n",
    "    if os.path.exists(file_path) and not redownload:\n",
    "        print(f\"The file {name} already exists in the directory. Skipping download.\")\n",
    "        return\n",
    "\n",
    "    r = requests.get(mast_url, params=params, headers=headers, stream=True)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    with open(file_path, \"wb\") as fobj:\n",
    "        for chunk in r.iter_content(chunk_size=1024000):\n",
    "            fobj.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015c6d5-07a3-4206-9495-3e9c9aae71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function for plotting the dark areas (the mask).\n",
    "\n",
    "def plot_dark_data(\n",
    "    rate_file,\n",
    "    mask_file,\n",
    "    cmap=\"viridis\",\n",
    "    scale=0.2,\n",
    "    slice_index=1,\n",
    "    axis=0,\n",
    "    aspect=\"auto\",\n",
    "    layout=\"rows\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the dark areas on the detector, masking out the illuminated areas.\n",
    "    This function can take 2D (_rate.fits) and 3D (_rateints.fits) files as input.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    rate_file: str\n",
    "        File path to the FITS file containing countrate data.\n",
    "    mask_file: str\n",
    "        File path to the FITS file containing mask data.\n",
    "    slice_index: int\n",
    "        Index of the slice to be plotted, 2D data default is 1.\n",
    "    axis: int (0-2)\n",
    "        Axis along which the slice will be taken\n",
    "        (0 for x-axis, 1 for y-axis, 2 for z-axis).\n",
    "    aspect: int or 'auto'\n",
    "        Plot's aspect ratio.\n",
    "    cmap: str\n",
    "        Color map.\n",
    "    layout: str\n",
    "        Layout subplots in rows or columns?\n",
    "    scale: float\n",
    "        Scaling factor applied to determine the intensity range for visualization.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make a matplotlib figure.\n",
    "    if layout == \"rows\":\n",
    "        fig, ax = plt.subplots(3, 1, figsize=(10, 5))\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    plt.suptitle(f\"Dark Areas for {os.path.basename(rate_file)}\", fontsize=15)\n",
    "\n",
    "    # Open the mask and science data.\n",
    "    with fits.open(mask_file) as hdulist:\n",
    "        mask = hdulist[1].data\n",
    "\n",
    "    with fits.open(rate_file) as hdulist:\n",
    "        sci = hdulist[\"SCI\"].data\n",
    "\n",
    "        # Determine if countrate data is 2D or 3D.\n",
    "        if len(sci.shape) == 3:\n",
    "            dim = 3\n",
    "        else:\n",
    "            dim = 2\n",
    "\n",
    "    # Get data limits from the dark data.\n",
    "    masked_sci = sci.copy()\n",
    "    masked_sci[mask == 0] = 0\n",
    "    vmin = np.nanpercentile(masked_sci, scale)\n",
    "    vmax = np.nanpercentile(masked_sci, 100 - scale)\n",
    "\n",
    "    # Plot the science image with limits from the dark data.\n",
    "    sci[np.isnan(sci)] = 0\n",
    "\n",
    "    # If the countrate data is 3D, determine the integration (slice) to plot.\n",
    "    if dim == 3:\n",
    "        sci = np.take(sci, slice_index, axis=axis)\n",
    "        mask = np.take(mask, slice_index, axis=axis)\n",
    "        masked_sci = np.take(masked_sci, slice_index, axis=axis)\n",
    "\n",
    "        ax[0].set_title(\"Original Rate Data: Integration [{},:,:]\".format(slice_index))\n",
    "        ax[1].set_title(\n",
    "            \"Illuminated Pixel Mask: Integration [{},:,:]\".format(slice_index)\n",
    "        )\n",
    "        ax[2].set_title(\n",
    "            \"Dark Data (Illuminated Pixels Masked): Integration [{},:,:]\".format(\n",
    "                slice_index\n",
    "            )\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        sci = sci\n",
    "        ax[0].set_title(\"Original Rate Data\")\n",
    "        ax[1].set_title(\"Illuminated Pixel Mask\")\n",
    "        ax[2].set_title(\"Dark Data (Illuminated Pixels Masked)\")\n",
    "\n",
    "    # Plot the science image with limits from the dark data.\n",
    "    ax[0].set_ylabel(\"Pixel Row\", fontsize=12)\n",
    "    ax[0].set_xlabel(\"Pixel Column\", fontsize=12)\n",
    "    im1 = ax[0].imshow(\n",
    "        sci, cmap=cmap, origin=\"lower\", aspect=aspect, vmin=vmin, vmax=vmax\n",
    "    )\n",
    "    cbar1 = fig.colorbar(im1, ax=ax[0], pad=0.05, shrink=0.7, label=\"DN/s\")\n",
    "\n",
    "    # Plot the mask: values are 1 or 0.\n",
    "    ax[1].set_ylabel(\"Pixel Row\", fontsize=12)\n",
    "    ax[1].set_xlabel(\"Pixel Column\", fontsize=12)\n",
    "    im2 = ax[1].imshow(mask, cmap=cmap, aspect=aspect, origin=\"lower\", vmin=0, vmax=1)\n",
    "    cbar2 = fig.colorbar(im2, ax=ax[1], pad=0.05, shrink=0.7, ticks=[0, 1])\n",
    "    cbar2.set_ticklabels([\"Illuminated Pixel Masked\", \"Un-Illuminated Pixel\"])\n",
    "\n",
    "    # Plot the dark data with the same limits as the science data.\n",
    "    ax[2].set_ylabel(\"Pixel Row\", fontsize=12)\n",
    "    ax[2].set_xlabel(\"Pixel Column\", fontsize=12)\n",
    "    im3 = ax[2].imshow(\n",
    "        masked_sci, cmap=cmap, aspect=aspect, origin=\"lower\", vmin=vmin, vmax=vmax\n",
    "    )\n",
    "    cbar3 = fig.colorbar(im3, ax=ax[2], pad=0.05, shrink=0.7, label=\"DN/s\")\n",
    "\n",
    "    if layout == \"rows\":  # Adjust the multiplier as needed.\n",
    "        cbar1.ax.figure.set_size_inches(cbar1.ax.figure.get_size_inches() * 1.2)\n",
    "        cbar2.ax.figure.set_size_inches(cbar2.ax.figure.get_size_inches() * 1.2)\n",
    "        cbar3.ax.figure.set_size_inches(cbar3.ax.figure.get_size_inches() * 1.2)\n",
    "\n",
    "    fig.tight_layout()  # Adjusted tight_layout for better suptitle spacing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b195d53-9fed-4bba-b2f4-36e07a2e2392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function for plotting the cleaned data.\n",
    "\n",
    "def plot_cleaned_data(\n",
    "    rate_file,\n",
    "    cleaned_file,\n",
    "    slice_indx=1,\n",
    "    aspect=\"auto\",\n",
    "    cmap=\"viridis\",\n",
    "    scale=0.2,\n",
    "    layout=\"rows\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the 2D cleaned rate data (or 2D slice from a 3D cleaned data cube)\n",
    "    and compare against the original data (not applying NSClean).\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    rate_file: str\n",
    "        File path to the FITS file containing original countrate data.\n",
    "    cleaned_file: str\n",
    "        File path to the FITS file containing cleaned countrate data.\n",
    "    slice_index: int\n",
    "        Index of the slice to be plotted, 2D data default is 1.\n",
    "    aspect: int or 'auto'\n",
    "        Plot's aspect ratio.\n",
    "    cmap: str\n",
    "        Color map.\n",
    "    layout: str\n",
    "        Layout subplots in rows or columns?\n",
    "    scale: float\n",
    "        Scaling factor applied to determine the intensity range for visualization.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make a matplotlib figure.\n",
    "    if layout == \"rows\":\n",
    "        fig, ax = plt.subplots(4, 1, figsize=(10, 12))\n",
    "    else:\n",
    "        fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        ax = ax.flatten()\n",
    "    plt.suptitle(\n",
    "        f\"Cleaned Data (1/f noise removed) for {os.path.basename(rate_file)}\",\n",
    "        fontsize=15,\n",
    "        y=1,\n",
    "    )\n",
    "\n",
    "    # Open the original and cleaned data.\n",
    "    with fits.open(rate_file) as hdulist:\n",
    "        original = hdulist[\"SCI\"].data\n",
    "\n",
    "    with fits.open(cleaned_file) as hdulist:\n",
    "        cleaned = hdulist[\"SCI\"].data\n",
    "        # Determine if rate data is 2D or 3D.\n",
    "        if len(cleaned.shape) == 3:\n",
    "            dim = 3\n",
    "        else:\n",
    "            dim = 2\n",
    "\n",
    "    # Define image limits from the original data.\n",
    "    vmin = np.nanpercentile(original, scale)\n",
    "    vmax = np.nanpercentile(original, 100 - scale)\n",
    "\n",
    "    original[np.isnan(original)] = 0\n",
    "    cleaned[np.isnan(cleaned)] = 0\n",
    "\n",
    "    # If the rate data is 3D, determine the integration (slice) to plot.\n",
    "    if dim == 3:\n",
    "        original = original[slice_indx, :, :]\n",
    "        cleaned = cleaned[slice_indx, :, :]\n",
    "        ax[0].set_title(\n",
    "            \"Original Rate Data: Integration [{},:,:]\".format(slice_indx), fontsize=15\n",
    "        )\n",
    "        ax[1].set_title(\n",
    "            \"Cleaned Rate Data: Integration [{},:,:]\".format(slice_indx), fontsize=15\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        ax[0].set_title(\"Original Rate Data\", fontsize=12)\n",
    "        ax[1].set_title(\"Cleaned Rate Data\", fontsize=12)\n",
    "\n",
    "    # Plot the original rate data.\n",
    "    ax[0].set_xlabel(\"Pixel Column\", fontsize=10)\n",
    "    ax[0].set_ylabel(\"Pixel Row\", fontsize=10)\n",
    "    fig.colorbar(\n",
    "        ax[0].imshow(\n",
    "            original, cmap=cmap, origin=\"lower\", aspect=aspect, vmin=vmin, vmax=vmax\n",
    "        ),\n",
    "        ax=ax[0],\n",
    "        pad=0.05,\n",
    "        shrink=0.7,\n",
    "        label=\"DN/s\",\n",
    "    )\n",
    "\n",
    "    # Plot the cleaned data with the same image limits.\n",
    "    ax[1].set_xlabel(\"Pixel Column\", fontsize=10)\n",
    "    ax[1].set_ylabel(\"Pixel Row\", fontsize=10)\n",
    "    fig.colorbar(\n",
    "        ax[1].imshow(\n",
    "            cleaned, cmap=cmap, origin=\"lower\", aspect=aspect, vmin=vmin, vmax=vmax\n",
    "        ),\n",
    "        ax=ax[1],\n",
    "        pad=0.05,\n",
    "        shrink=0.7,\n",
    "        label=\"DN/s\",\n",
    "    )\n",
    "\n",
    "    # Plot the relative difference between the original and cleaned data.\n",
    "    diff = (original - cleaned) / original\n",
    "    diff[~np.isfinite(diff)] = 0\n",
    "    vmin_diff = np.nanpercentile(diff, scale)\n",
    "    vmax_diff = np.nanpercentile(diff, 100 - scale)\n",
    "    ax[2].set_title(\"Relative Difference (Original - Cleaned Rate Data)\", fontsize=12)\n",
    "    ax[2].set_xlabel(\"Pixel Column\", fontsize=10)\n",
    "    ax[2].set_ylabel(\"Pixel Row\", fontsize=10)\n",
    "    fig.colorbar(\n",
    "        ax[2].imshow(\n",
    "            diff,\n",
    "            cmap=cmap,\n",
    "            origin=\"lower\",\n",
    "            aspect=aspect,\n",
    "            vmin=vmin_diff,\n",
    "            vmax=vmax_diff,\n",
    "        ),\n",
    "        ax=ax[2],\n",
    "        pad=0.05,\n",
    "        shrink=0.7,\n",
    "        label=\"DN/s\",\n",
    "    )\n",
    "\n",
    "    # Plot the relative difference again,\n",
    "    # this time hiding the outliers so that low-level\n",
    "    # background changes can be seen.\n",
    "    hide_outliers = np.ma.filled(sigma_clip(diff, masked=True), fill_value=0)\n",
    "    vmin_outliers = np.nanpercentile(hide_outliers, scale)\n",
    "    vmax_outliers = np.nanpercentile(hide_outliers, 100 - scale)\n",
    "    ax[3].set_title(\n",
    "        \"Relative Difference (Original - Cleaned Rate Data) \\n with Outliers Hidden\",\n",
    "        fontsize=12,\n",
    "    )\n",
    "    ax[3].set_xlabel(\"Pixel Column\", fontsize=10)\n",
    "    ax[3].set_ylabel(\"Pixel Row\", fontsize=10)\n",
    "    fig.colorbar(\n",
    "        ax[3].imshow(\n",
    "            hide_outliers,\n",
    "            cmap=cmap,\n",
    "            origin=\"lower\",\n",
    "            aspect=aspect,\n",
    "            vmin=vmin_outliers,\n",
    "            vmax=vmax_outliers,\n",
    "        ),\n",
    "        ax=ax[3],\n",
    "        pad=0.05,\n",
    "        shrink=0.7,\n",
    "        label=\"DN/s\",\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6fae03-79fc-479c-9802-d3484b23283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function for plotting the 1D spectra.\n",
    "\n",
    "def plot_spectra(\n",
    "    spec_list,\n",
    "    ext_num=1,\n",
    "    scale_percent=2.0,\n",
    "    wavelength_range=None,\n",
    "    flux_range=None,\n",
    "    xlim_low=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the cleaned extracted 1D spectrum and compare against\n",
    "    the original (not applying NSClean) extracted 1D spectrum.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    spec_list: list\n",
    "        List of paths to the FITS files containing original/cleaned 1D extracted data.\n",
    "    scale_percent: float\n",
    "        Scaling factor applied to determine the intensity range for visualization.\n",
    "    ext_num: int\n",
    "        Index/extension of the slice to be plotted.\n",
    "        The EXTVER header value. The default is 1 for 2D data.\n",
    "    wavelength_range: dict\n",
    "        Wavelength range (x-axis) {'nrs1': [3.6, 3.65], 'nrs2': [1.65, 1.75]}.\n",
    "    flux_range: dict\n",
    "        Flux range (y-axis) {'nrs1': [1, 2], 'nrs2': [1, 2]}.\n",
    "    xlim_low: int\n",
    "        Define a lower wavelengh end for the 1D spectrum. Helpful for BOTS data.\n",
    "    \"\"\"\n",
    "\n",
    "    if wavelength_range is None:\n",
    "        wavelength_range = {}\n",
    "\n",
    "    # Open the FITS files.\n",
    "    original_hdul = fits.open(spec_list[0])\n",
    "    cleaned_hdul = fits.open(spec_list[1])\n",
    "    if len(spec_list) == 3:\n",
    "        alternate_hdul = fits.open(spec_list[2])\n",
    "    elif len(spec_list) == 4:\n",
    "        alternate_hdul = fits.open(spec_list[2])\n",
    "        handmod_hdul = fits.open(spec_list[3])\n",
    "    else:\n",
    "        alternate_hdul = None\n",
    "        handmod_hdul = None\n",
    "\n",
    "    # Find the spectral extension (EXTRACT1D).\n",
    "    for extnum in range(len(original_hdul)):\n",
    "        hdu = original_hdul[extnum]\n",
    "        if hdu.name != \"EXTRACT1D\":\n",
    "            continue\n",
    "        slit_name = hdu.header[\"SLTNAME\"]\n",
    "\n",
    "        if hdu.header[\"EXTVER\"] == ext_num:\n",
    "\n",
    "            # Plot the original and cleaned spectra together.\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            plt.suptitle(\n",
    "                f\"Compare 1D Spectra for {os.path.basename(spec_list[0])};\"\n",
    "                f\"EXP_TYPE/Slit = {slit_name}\",\n",
    "                fontsize=15,\n",
    "            )\n",
    "\n",
    "            if \"nrs1\" in spec_list[0] and xlim_low is not None:\n",
    "                xlim_low = xlim_low\n",
    "            else:\n",
    "                xlim_low = 0\n",
    "\n",
    "            ax[0].step(\n",
    "                hdu.data[\"WAVELENGTH\"][xlim_low:],\n",
    "                hdu.data[\"FLUX\"][xlim_low:],\n",
    "                linewidth=1,\n",
    "                label=\"Original\",\n",
    "            )\n",
    "            ax[0].step(\n",
    "                cleaned_hdul[extnum].data[\"WAVELENGTH\"][xlim_low:],\n",
    "                cleaned_hdul[extnum].data[\"FLUX\"][xlim_low:],\n",
    "                linewidth=1,\n",
    "                label=\"Cleaned\",\n",
    "            )\n",
    "            ax[0].set_xlabel(f\"Wavelength ({hdu.header['TUNIT1']})\", fontsize=12)\n",
    "            ax[0].set_ylabel(f\"Flux ({hdu.header['TUNIT2']})\", fontsize=12)\n",
    "            ax[0].set_title(\"1D Extracted Spectra\", fontsize=12)\n",
    "\n",
    "            # Plot the difference between the spectra as a ratio.\n",
    "            diff = (\n",
    "                cleaned_hdul[extnum].data[\"FLUX\"][xlim_low:]\n",
    "                / hdu.data[\"FLUX\"][xlim_low:]\n",
    "            )\n",
    "            ax[1].step(\n",
    "                hdu.data[\"WAVELENGTH\"][xlim_low:],\n",
    "                diff,\n",
    "                linewidth=1,\n",
    "                label=\"Cleaned/Original\",\n",
    "            )\n",
    "            ax[1].set_xlabel(f\"Wavelength ({hdu.header['TUNIT1']})\", fontsize=12)\n",
    "            ax[1].set_ylabel(\"Cleaned/Original\", fontsize=12)\n",
    "            ax[1].set_title(\"Difference After Cleaning\", fontsize=12)\n",
    "            # print(\"Average Difference  = {}\".format(np.nanmean(diff)))\n",
    "\n",
    "            # If available, also plot the alternate spectra.\n",
    "            if alternate_hdul is not None:\n",
    "                ax[0].step(\n",
    "                    alternate_hdul[extnum].data[\"WAVELENGTH\"][xlim_low:],\n",
    "                    alternate_hdul[extnum].data[\"FLUX\"][xlim_low:],\n",
    "                    linewidth=1,\n",
    "                    label=\"Cleaned (alternate mask)\",\n",
    "                )\n",
    "                diff2 = (\n",
    "                    alternate_hdul[extnum].data[\"FLUX\"][xlim_low:]\n",
    "                    / hdu.data[\"FLUX\"][xlim_low:]\n",
    "                )\n",
    "                ax[1].step(\n",
    "                    hdu.data[\"WAVELENGTH\"][xlim_low:],\n",
    "                    diff2,\n",
    "                    linewidth=1,\n",
    "                    label=\"Cleaned (alternate mask)/Original\",\n",
    "                )\n",
    "            if handmod_hdul is not None:\n",
    "\n",
    "                ax[0].step(\n",
    "                    handmod_hdul[extnum].data[\"WAVELENGTH\"][xlim_low:],\n",
    "                    handmod_hdul[extnum].data[\"FLUX\"][xlim_low:],\n",
    "                    linewidth=1,\n",
    "                    label=\"Cleaned (hand-modified mask)\",\n",
    "                )\n",
    "                diff3 = (\n",
    "                    handmod_hdul[extnum].data[\"FLUX\"][xlim_low:]\n",
    "                    / hdu.data[\"FLUX\"][xlim_low:]\n",
    "                )\n",
    "                ax[1].step(\n",
    "                    hdu.data[\"WAVELENGTH\"][xlim_low:],\n",
    "                    diff3,\n",
    "                    linewidth=1,\n",
    "                    label=\"Cleaned (hand-modified mask)/Original\",\n",
    "                )\n",
    "\n",
    "            # Set the y-range of the plot if needed.\n",
    "            if flux_range is not None:\n",
    "                for key, y_range in flux_range.items():\n",
    "                    if key.lower() in spec_list[0].lower() and y_range is not None:\n",
    "                        if len(y_range) == 2:\n",
    "                            ax[0].set_ylim(y_range)\n",
    "                            ax[1].set_ylim(\n",
    "                                [\n",
    "                                    np.nanpercentile(diff, scale_percent),\n",
    "                                    np.nanpercentile(diff, 100 - scale_percent),\n",
    "                                ]\n",
    "                            )\n",
    "                            # ax[1].set_ylim(0.5, 1.5)\n",
    "\n",
    "                        else:\n",
    "                            all_flux = [\n",
    "                                hdu.data[\"FLUX\"],\n",
    "                                cleaned_hdul[extnum].data[\"FLUX\"],\n",
    "                            ]\n",
    "                            y_range_ax0 = [\n",
    "                                np.nanpercentile(all_flux[0], scale_percent),\n",
    "                                np.nanpercentile(all_flux[0], 100 - scale_percent),\n",
    "                            ]\n",
    "                            ax[0].set_ylim(y_range_ax0)\n",
    "                            # ax[1].set_ylim(0.5, 1.5)\n",
    "\n",
    "                            ax[1].set_ylim(\n",
    "                                [\n",
    "                                    np.nanpercentile(diff, scale_percent),\n",
    "                                    np.nanpercentile(diff, 100 - scale_percent),\n",
    "                                ]\n",
    "                            )\n",
    "\n",
    "            else:\n",
    "                all_flux = [hdu.data[\"FLUX\"], cleaned_hdul[extnum].data[\"FLUX\"]]\n",
    "                y_range_ax0 = [\n",
    "                    np.nanpercentile(all_flux[0], scale_percent),\n",
    "                    np.nanpercentile(all_flux[0], 100 - scale_percent),\n",
    "                ]\n",
    "                ax[0].set_ylim(y_range_ax0)\n",
    "                # ax[1].set_ylim(0.5, 1.5)\n",
    "\n",
    "                ax[1].set_ylim(\n",
    "                    [\n",
    "                        np.nanpercentile(diff, scale_percent),\n",
    "                        np.nanpercentile(diff, 100 - scale_percent),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            # Set the x-range of the plot if needed.\n",
    "            for key in wavelength_range:\n",
    "                if key in spec_list[0] and wavelength_range[key] is not None:\n",
    "                    ax[0].set_xlim(wavelength_range[key])\n",
    "                    ax[1].set_xlim(wavelength_range[key])\n",
    "\n",
    "            fig.tight_layout()\n",
    "\n",
    "            ax[0].legend()\n",
    "            ax[1].legend()\n",
    "\n",
    "    original_hdul.close()\n",
    "    cleaned_hdul.close()\n",
    "    if alternate_hdul is not None:\n",
    "        alternate_hdul.close()\n",
    "        handmod_hdul.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bafbdb-d55b-4e31-bc4e-97e0fb8f67b1",
   "metadata": {},
   "source": [
    "## 4. Download the Data <a name=\"data\"></a>\n",
    "<hr style=\"border:1px solid black\">\n",
    " \n",
    "The input data for this notebook features an IFU observation of quasar XID2028 with grating/filter G140H/F100LP. The dataset is part of the [JWST Early Release Science program ERS-1335](https://www.stsci.edu/jwst/science-execution/approved-programs/dd-ers/program-1335), specifically observation 4. It consists of 9 integrations (9 dither points) with 16 groups each. This notebook focuses on the second dithered exposure (00002) as an example. However, it's important to note that before proceeding to the `Spec3Pipeline`, all exposures must first be processed through the `Spec2Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9776be-c6e8-4588-8712-e0516bc6bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a downloads directory.\n",
    "mast_products_dir = \"./mast_products/\"\n",
    "# Check if the directory exists.\n",
    "if not os.path.exists(mast_products_dir):\n",
    "    # Create the directory if it doesn't exist.\n",
    "    os.makedirs(mast_products_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6601f0-45d7-4bd0-ba57-a6401ab529f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook focuses on the second dithered exposure.\n",
    "obs_ids = [\"jw01335004001_03101_00002\"]\n",
    "detectors = [1, 2]  # Both Detectors NRS1 and NRS2.\n",
    "\n",
    "# Specify the countrate products.\n",
    "rate_names = []\n",
    "\n",
    "for obs_id in obs_ids:\n",
    "    for detector in detectors:\n",
    "        rate_names.append(f\"{obs_id}_nrs{detector}_rate.fits\")\n",
    "\n",
    "# Download all the FITS files.\n",
    "for name in rate_names:\n",
    "    print(f\"Downloading {name}\")\n",
    "    get_jwst_file(name, mast_api_token=None, save_directory=mast_products_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302c90c6-3c42-4710-becc-49533b69de70",
   "metadata": {},
   "source": [
    "## 5. Running `Spec2Pipeline` without NSClean (Original Data) <a name=\"nsclean_skipped\"></a>\n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "The cell below executes the `Spec2Pipeline`, explicitly skipping the NSClean step during processing. The level 2 products generated will serve as a reference point to illustrate how the countrate images and final extracted spectra appear without the removal of 1/f noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d87880-8591-43a3-80b7-a6a09147a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directory for running the pipeline without NSClean.\n",
    "stage2_nsclean_skipped_dir = \"./stage2_nsclean_skipped/\"\n",
    "if not os.path.exists(stage2_nsclean_skipped_dir):\n",
    "    os.makedirs(stage2_nsclean_skipped_dir)  # Create the directory if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9917bd4-6e79-4e43-9864-d7fb6d970b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original data (no NSClean Applied).\n",
    "# Estimated run-time: 132 minutes (may vary).\n",
    "start = tt.time()\n",
    "\n",
    "for i in rate_names:\n",
    "    print(f\"Processing {i}...\")\n",
    "\n",
    "    Spec2Pipeline.call(\n",
    "        mast_products_dir + i,\n",
    "        save_results=True,\n",
    "        steps={\n",
    "            \"nsclean\": {\n",
    "                \"skip\": True\n",
    "            },  # Removes correlated read noise (1/f noise) from NIRSpec images.\n",
    "        },\n",
    "        output_dir=stage2_nsclean_skipped_dir,\n",
    "    )\n",
    "\n",
    "    print(f\"Saved {i[:-9]}\" + \"cal.fits\")\n",
    "    print(f\"Saved {i[:-9]}\" + \"x1d.fits\")\n",
    "\n",
    "\n",
    "end = tt.time()\n",
    "print(\"Run time: \", round(end - start, 1) / 60.0, \" min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b99dc71-32ca-4599-b598-e64ea206f9d2",
   "metadata": {},
   "source": [
    "## 6. Clean up 1/f Noise with NSClean (Default Pipeline Mask) <a name=\"nsclean_default\"></a>\n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "If a user-supplied mask file is not provided to the [NSClean step](https://jwst-pipeline.readthedocs.io/en/latest/jwst/nsclean/index.html) in the `Spec2Pipeline`, the pipeline will generate a mask based on default parameters. This mask will identify any pixel that is unilluminated. That is, the mask must contain True and False values, where True indicates that the pixel is dark, and False indicates that the pixel is illuminated (not dark).\n",
    "\n",
    "By default, the pipeline marks the following detector areas as illuminated, non-dark areas (False):\n",
    "\n",
    "* Pixels designated as science areas for IFU data.\n",
    "* Traces from failed-open MSA shutters.\n",
    "* 5-sigma outliers (default value). \n",
    "* Any pixel set to NaN in the rate data.\n",
    "\n",
    "To tune the outlier detection in the mask, try modifying the `n_sigma` parameter (explored in the next section). A higher value will identify fewer outliers. A lower value will identify more. \n",
    "\n",
    "The default generated mask is saved and analyzed below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22165874-0081-47d5-8373-916829abad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directory for running NSClean with default parameters.\n",
    "stage2_nsclean_default_dir = \"./stage2_nsclean_default/\"\n",
    "if not os.path.exists(stage2_nsclean_default_dir):\n",
    "    os.makedirs(stage2_nsclean_default_dir)  # Create the directory if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a7ebdd-6f5d-491f-8dce-645070115165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/f noise cleaned data (default NSClean pipeline mask).\n",
    "# Estimated run time: 105 minutes (may vary).\n",
    "start = tt.time()\n",
    "\n",
    "for i in rate_names:\n",
    "    print(f\"Processing {i}...\")\n",
    "\n",
    "    Spec2Pipeline.call(\n",
    "        mast_products_dir + i,\n",
    "        save_results=True,\n",
    "        steps={\n",
    "            \"nsclean\": {\n",
    "                \"skip\": False,\n",
    "                \"save_mask\": True,\n",
    "                \"save_results\": True,\n",
    "            },  # Removes correlated read noise (1/f noise) from NIRSpec images.\n",
    "        },\n",
    "        output_dir=stage2_nsclean_default_dir,\n",
    "    )\n",
    "\n",
    "    print(f\"Saved {i[:-9]}\" + \"mask.fits\")\n",
    "    print(f\"Saved {i[:-9]}\" + \"nsclean.fits\")\n",
    "    print(f\"Saved {i[:-9]}\" + \"cal.fits\")\n",
    "    print(f\"Saved {i[:-9]}\" + \"x1d.fits\")\n",
    "\n",
    "\n",
    "end = tt.time()\n",
    "print(\"Run time: \", round(end - start, 1) / 60.0, \" min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc87c93-9e8a-4041-9e57-32d80f17d91a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> \n",
    "    \n",
    "In some situations, the NSClean step may fail to find a fit to the background noise. This failure may occur if the mask does not contain enough dark data (marked True). In particular, every column in the mask except for the first and last 4 columns must contain some pixels marked True. The background fitting procedure considers each column, one at a time, so it will crash if there is no data in a column to fit. If failure occurs, check that your mask in the image below has at least some True values in every column.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c5f2cf-d7a3-4606-bc92-46b3b73cfb29",
   "metadata": {},
   "source": [
    "### 6.1 Verify the Mask (Default Pipeline Mask) <a name=\"verify_default_mask\"></a>\n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "Check the mask against the rate data to make sure it keeps only dark areas of the detector.\n",
    "\n",
    "Note that there are still some remaining illuminated areas, primarily due to transient artifacts like cosmic rays and snowballs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff98268-379a-4712-9b22-b05289eb7edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the rate data with masked areas blocked.\n",
    "\n",
    "# List of on-the-fly built masks from the pipeline.\n",
    "nsclean_default_masks = [\n",
    "    stage2_nsclean_default_dir + \"jw01335004001_03101_00002_nrs1_mask.fits\",\n",
    "    stage2_nsclean_default_dir + \"jw01335004001_03101_00002_nrs2_mask.fits\",\n",
    "]\n",
    "\n",
    "# Plot each associated set of rateint data and mask file.\n",
    "for rate_file, mask_file in zip(rate_names, nsclean_default_masks):\n",
    "    plot_dark_data(mast_products_dir + rate_file, mask_file, layout=\"columns\", scale=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4c5b7b-4dd6-4d6c-9ae3-5590ab9131b9",
   "metadata": {},
   "source": [
    "### 6.2 Comparing Original vs. Cleaned Data (Default Pipeline Mask) <a name=\"nsclean_default_compare\"></a>\n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "We can now compare the cleaned data (with the default pipeline mask) to the original rate file and verify that the 1/f noise has been reduced.\n",
    "\n",
    "In many cases, the cleaning process introduces new artifacts to the rate file. These should be carefully examined and weighed against the benefits of noise reduction. If transient artifacts, like snowballs, are interfering with the cleaning process, it may be beneficial to manually edit the mask to remove these areas from consideration in the background fit. To do so, try varying the outlier detection threshold or editing specific pixels in the mask array directly (explored in the next few sections). Otherwise, refer to the [NSClean documentation](https://iopscience.iop.org/article/10.1088/1538-3873/ad1b36/pdf) for additional suggestions on manual editing.\n",
    "\n",
    "Note that in the images below, there are scattered values with large relative differences from the original rate file (shown in the relative difference image below). These are artifacts of the cleaning process.\n",
    "\n",
    "There are also broader low-level residual background effects (shown in the relative difference image on the right, below, with scattered outliers, identified with sigma clipping, hidden by masking). These include the background patterns we are trying to remove: the 1/f noise variations in the dispersion direction and the picture frame effect at the top and bottom of the frame (for full-frame data). However, there may also be low-level artifacts introduced by over-fitting the dark data in the cleaning process.\n",
    "\n",
    "Check both residual images carefully to understand the impact of the cleaning process on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0bb29c-b1a1-4bf7-9b22-62696cd6f9e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the original and cleaned data, as well as a residual map.\n",
    "\n",
    "cleaned_default_masks = [\n",
    "    stage2_nsclean_default_dir + \"jw01335004001_03101_00002_nrs1_nsclean.fits\",\n",
    "    stage2_nsclean_default_dir + \"jw01335004001_03101_00002_nrs2_nsclean.fits\",\n",
    "]\n",
    "\n",
    "# Plot each associated set of rateint data and cleaned file.\n",
    "for rate_file, cleaned_file in zip(rate_names, cleaned_default_masks):\n",
    "    plot_cleaned_data(\n",
    "        mast_products_dir + rate_file, cleaned_file, layout=\"columns\", scale=9\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e2ed06-5604-4feb-826b-6fd6bcf72122",
   "metadata": {},
   "source": [
    "Compare the extracted spectrum from the cleaned data to the spectrum extracted from the original rate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecfa71-ff48-4715-b690-18776b84aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D extracted spectra.\n",
    "x1d_nsclean_skipped = [\n",
    "    stage2_nsclean_skipped_dir + \"jw01335004001_03101_00002_nrs1_x1d.fits\",\n",
    "    stage2_nsclean_skipped_dir + \"jw01335004001_03101_00002_nrs2_x1d.fits\",\n",
    "]\n",
    "x1d_nsclean_default = [\n",
    "    stage2_nsclean_default_dir + \"jw01335004001_03101_00002_nrs1_x1d.fits\",\n",
    "    stage2_nsclean_default_dir + \"jw01335004001_03101_00002_nrs2_x1d.fits\",\n",
    "]\n",
    "\n",
    "# Wavelength region of interest.\n",
    "wavelength_range = {\"nrs1\": [1.15, 1.25], \"nrs2\": [1.65, 1.75]}\n",
    "for original, cleaned in zip(x1d_nsclean_skipped, x1d_nsclean_default):\n",
    "    plot_spectra(\n",
    "        [original, cleaned], scale_percent=4, wavelength_range=wavelength_range\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07074551-7ce7-4144-90f5-29f682922205",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Notes:</b> \n",
    "* The portion of the spectrum near 1.2um for NRS1 and 1.7um for NRS2, the excess flux due to 1/f noise is reduced.\n",
    "* There are several spikes in the difference between the cleaned and original spectra. These correspond to the scattered artifacts introduced by the cleaning process, above.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f85a17-cb1c-4320-a3bd-1800fa02bab9",
   "metadata": {},
   "source": [
    "## 7. Clean up 1/f Noise with NSClean (Alternate Mask) <a name=\"nsclean_alternate\"></a>\n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "For some data sets, masking the entire science region may excessively mask dark areas of the detector that could be used to improve the background fit. Excessive masking can introduce some high frequency noise in the cleaning process that appears as vertical striping over the spectral traces. Also, for some data sets, there may be several illuminated regions of the detector that are not masked by the IFU slice bounding boxes. This may include transient artifacts like cosmic rays or glow from saturated sources.\n",
    "\n",
    "In some cases, it may be beneficial to build the mask with an alternate algorithm.  Here, we do not use the bounding boxes and instead iteratively mask any data more than 1 sigma above the background. For bright sources, this might leave more dark data between the spectral traces and may improve the background fit. \n",
    "\n",
    "Note, however, that excessive cleaning may impact the continuum level for the spectrum, if too much or too little illuminated data is included in the mask. Again, the generated mask and output spectra should be carefully examined to weigh the benefits of cleaning against the impact on the spectra.\n",
    "\n",
    "To tune the illumination detection in this mask, try modifying the `n_sigma` parameter below. A higher value will identify less illumination. A lower value will identify more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b47885-df6d-4737-b934-b16652e657dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directory for running NSClean with user-supplied mask.\n",
    "stage2_nsclean_alternate_dir = \"./stage2_nsclean_alternate/\"\n",
    "if not os.path.exists(stage2_nsclean_alternate_dir):\n",
    "    os.makedirs(\n",
    "        stage2_nsclean_alternate_dir\n",
    "    )  # Create the directory if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02336a18-5741-4571-9b38-ecb50f7ced08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/f noise cleaned data (alternate NSClean pipeline mask).\n",
    "# Estimated run time: 87 minutes (may vary).\n",
    "start = tt.time()\n",
    "\n",
    "for indx, i in enumerate(rate_names):\n",
    "    print(f\"Processing {i}... \")\n",
    "\n",
    "    Spec2Pipeline.call(\n",
    "        mast_products_dir + i,\n",
    "        save_results=True,\n",
    "        steps={\n",
    "            \"nsclean\": {\n",
    "                \"skip\": False,\n",
    "                \"save_mask\": True,\n",
    "                \"n_sigma\": 1,\n",
    "                \"mask_spectral_regions\": False,\n",
    "                \"save_results\": True,\n",
    "            },  # Removes correlated read noise (1/f noise) from NIRSpec images.\n",
    "        },\n",
    "        output_dir=stage2_nsclean_alternate_dir,\n",
    "    )\n",
    "\n",
    "    print(f\"Saved {i[:-9]}\" + \"mask.fits\")\n",
    "    print(f\"Saved {i[:-9]}\" + \"nsclean.fits\")\n",
    "    print(f\"Saved {i[:-9]}\" + \"cal.fits\")\n",
    "    print(f\"Saved {i[:-9]}\" + \"x1d.fits\")\n",
    "\n",
    "end = tt.time()\n",
    "print(\"Run time: \", round(end - start, 1) / 60.0, \" min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef33421e-bd16-41d0-883d-4a68202897b6",
   "metadata": {},
   "source": [
    "### 7.1 Verify the Mask (Alternate Mask) <a name=\"verify_alternate_mask\"></a>\n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "Check the mask against the rate data to make sure it keeps only dark areas of the detector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0d7dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the rate data with masked areas blocked.\n",
    "\n",
    "# List of on-the-fly built masks from the pipeline.\n",
    "nsclean_alternate_masks = [\n",
    "    stage2_nsclean_alternate_dir + \"jw01335004001_03101_00002_nrs1_mask.fits\",\n",
    "    stage2_nsclean_alternate_dir + \"jw01335004001_03101_00002_nrs2_mask.fits\",\n",
    "]\n",
    "\n",
    "# Plot each associated set of rateint data and mask file.\n",
    "for rate_file, mask_file in zip(rate_names, nsclean_alternate_masks):\n",
    "    plot_dark_data(mast_products_dir + rate_file, mask_file, layout=\"columns\", scale=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84cca59-2781-437d-a169-fa5c9e012b3a",
   "metadata": {},
   "source": [
    "### 7.2 Comparing Original vs. Cleaned Data (Alternate Mask) <a name=\"nsclean_alternate_compare\"></a>\n",
    "<hr style=\"border:1px solid black\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e8929-ef97-4673-b985-dbcf5eba6be5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the original and cleaned data, as well as a residual map.\n",
    "\n",
    "cleaned_alternate_masks = [\n",
    "    stage2_nsclean_alternate_dir + \"jw01335004001_03101_00002_nrs1_nsclean.fits\",\n",
    "    stage2_nsclean_alternate_dir + \"jw01335004001_03101_00002_nrs2_nsclean.fits\",\n",
    "]\n",
    "\n",
    "# Plot each associated set of rateint data and cleaned file.\n",
    "for rate_file, cleaned_file in zip(rate_names, cleaned_alternate_masks):\n",
    "    plot_cleaned_data(\n",
    "        mast_products_dir + rate_file, cleaned_file, layout=\"columns\", scale=9\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6376544c-12fc-45dc-9dce-0ac2b4a8ec77",
   "metadata": {},
   "source": [
    "Compare the extracted spectrum from the cleaned data to the spectrum extracted from the original rate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee33a68-ca76-4a2c-b38e-2e0fa444b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1d_nsclean_alternate = [\n",
    "    stage2_nsclean_alternate_dir + \"jw01335004001_03101_00002_nrs1_x1d.fits\",\n",
    "    stage2_nsclean_alternate_dir + \"jw01335004001_03101_00002_nrs2_x1d.fits\",\n",
    "]\n",
    "\n",
    "# Wavelength region of interest.\n",
    "wavelength_range = {\"nrs1\": [1.15, 1.25], \"nrs2\": [1.65, 1.75]}\n",
    "for original, cleaned in zip(x1d_nsclean_skipped, x1d_nsclean_alternate):\n",
    "    plot_spectra(\n",
    "        [original, cleaned], scale_percent=4, wavelength_range=wavelength_range\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f88a25-3262-42dc-89f8-986df2f8e2e1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Notes:</b> \n",
    "* The overall continuum level for the spectrum on NRS1 has changed after cleaning. This is because sigma-clipping, unlike the default method, only masks the bright outliers, rather than the entire science region. Consequently, some sky regions are included in the background model that gets subtracted from the data, which can result in changes to the continuum level.\n",
    "* The portion of the spectrum near 1.7um for NRS2, the excess flux due to 1/f noise is reduced.\n",
    "* There are several spikes in the difference between the cleaned and original spectra. These correspond to the scattered artifacts introduced by the cleaning process, above.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec75731",
   "metadata": {},
   "source": [
    "## 8. Clean up 1/f Noise with NSClean (Hand-Modified Mask) <a name=\"nsclean_modified\"></a>\n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "In certain scenarios, manual generation of a mask may be required. Here, we present **one** approach to manually modify the mask (excluding some large snowballs in NRS1/NRS2) starting with the default mask output from the pipeline. It is worth noting that the mask modified using this method may not necessarily outperform the two previous options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688909d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directory for running NSClean with user-supplied mask.\n",
    "stage2_nsclean_modified_dir = \"./stage2_nsclean_modified/\"\n",
    "if not os.path.exists(stage2_nsclean_modified_dir):\n",
    "    # Create the directory if it doesn't exist.\n",
    "    os.makedirs(stage2_nsclean_modified_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee4a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hand-modify certain mask regions\n",
    "# Snowballs in NRS1/2.\n",
    "\n",
    "# Define the list to store paths of modified masks.\n",
    "nsclean_modified_masks = []\n",
    "\n",
    "# Iterate through the list of original masks.\n",
    "for mask in nsclean_default_masks:\n",
    "    # New mask file name.\n",
    "    output_file = os.path.basename(mask)[:-5] + \"_modified.fits\"\n",
    "\n",
    "    # Open the FITS file.\n",
    "    with fits.open(mask) as hdul:\n",
    "        # Extract the mask data from the science extension.\n",
    "        mask_data = hdul[\"SCI\"].data.copy()  # Make a copy.\n",
    "\n",
    "        if \"nrs1\" in mask:\n",
    "            # Mask Snowballs.\n",
    "            mask_data[10:50, 180:215] = False\n",
    "            mask_data[560:580, 450:465] = False\n",
    "            mask_data[1720:1810, 1150:1240] = False\n",
    "            mask_data[1540:1580, 535:580] = False\n",
    "            mask_data[1865:1910, 725:770] = False\n",
    "        else:\n",
    "            mask_data[200:250, 130:190] = False\n",
    "            mask_data[1400:1420, 40:80] = False\n",
    "            mask_data[1700:1730, 150:180] = False\n",
    "            mask_data[630:710, 1100:1170] = False\n",
    "            mask_data[520:570, 1770:1820] = False\n",
    "\n",
    "        # Update the data within the science extension.\n",
    "        hdul[\"SCI\"].data = mask_data\n",
    "        # Save the modified FITS file.\n",
    "        output_path = os.path.join(stage2_nsclean_modified_dir, output_file)\n",
    "        hdul_modified = hdul.copy()  # Make a copy.\n",
    "        hdul_modified.writeto(output_path, overwrite=True)\n",
    "        nsclean_modified_masks.append(output_path)\n",
    "        print(f\"Saved modified mask as: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463ae320-2f8e-4c5a-9a47-d1698c33704e",
   "metadata": {},
   "source": [
    "### 8.1 Verify the Mask (Hand-Modified Mask) <a name=\"verify_modified_mask\"></a>\n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "Check the mask against the rate data to make sure it keeps only dark areas of the detector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46cf4cc-a75b-4c0d-97b1-ff62bc0985d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the rate data with masked areas blocked.\n",
    "\n",
    "# List of modified masks for the pipeline.\n",
    "nsclean_modified_masks = [\n",
    "    stage2_nsclean_modified_dir + \"jw01335004001_03101_00002_nrs1_mask_modified.fits\",\n",
    "    stage2_nsclean_modified_dir + \"jw01335004001_03101_00002_nrs2_mask_modified.fits\",\n",
    "]\n",
    "\n",
    "# Plot each associated set of rateint data and mask file.\n",
    "for rate_file, mask_file in zip(rate_names, nsclean_modified_masks):\n",
    "    plot_dark_data(mast_products_dir + rate_file, mask_file, layout=\"columns\", scale=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061f850b-404f-4476-84a0-5e88a80e0fc0",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a70729-8ffe-4cc1-a7e6-46e8d7b08038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/f noise cleaned data (user-supplied mask).\n",
    "# Estimated run time: 87 minutes (may vary).\n",
    "start = tt.time()\n",
    "\n",
    "for indx, i in enumerate(rate_names):\n",
    "    print(f\"Processing {i}... \")\n",
    "\n",
    "    Spec2Pipeline.call(\n",
    "        mast_products_dir + i,\n",
    "        save_results=True,\n",
    "        steps={\n",
    "            \"nsclean\": {\n",
    "                \"skip\": False,\n",
    "                \"save_mask\": True,\n",
    "                \"save_results\": True,\n",
    "                \"user_mask\": nsclean_modified_masks[indx],\n",
    "            },  # Removes correlated read noise (1/f noise) from NIRSpec images.\n",
    "        },\n",
    "        output_dir=stage2_nsclean_modified_dir,\n",
    "    )\n",
    "\n",
    "    print(f\"Saved {i[:-9]}\" + \"mask.fits\")\n",
    "    print(f\"Saved {i[:-9]}\" + \"nsclean.fits\")\n",
    "    print(f\"Saved {i[:-9]}\" + \"cal.fits\")\n",
    "    print(f\"Saved {i[:-9]}\" + \"x1d.fits\")\n",
    "\n",
    "\n",
    "end = tt.time()\n",
    "print(\"Run time: \", round(end - start, 1) / 60.0, \" min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36753340-5509-4fec-91a4-3b1dcfe63075",
   "metadata": {},
   "source": [
    "### 8.2 Comparing Original vs. Cleaned Data (Hand-Modified Mask) <a name=\"nsclean_modified_compare\"></a>\n",
    "<hr style=\"border:1px solid black\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b12c21-2dce-4065-a951-b79b22f79b54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the original and cleaned data, as well as a residual map.\n",
    "\n",
    "cleaned_modified_masks = [\n",
    "    stage2_nsclean_modified_dir + \"jw01335004001_03101_00002_nrs1_nsclean.fits\",\n",
    "    stage2_nsclean_modified_dir + \"jw01335004001_03101_00002_nrs2_nsclean.fits\",\n",
    "]\n",
    "\n",
    "# Plot each associated set of rateint data and cleaned file.\n",
    "for rate_file, cleaned_file in zip(rate_names, cleaned_modified_masks):\n",
    "    plot_cleaned_data(\n",
    "        mast_products_dir + rate_file, cleaned_file, layout=\"columns\", scale=9\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b37f102-5db8-475b-98ec-740fb6086fe4",
   "metadata": {},
   "source": [
    "Compare the extracted spectrum from the cleaned data to the spectrum extracted from the original rate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb631e-6e0e-4d4d-a9b0-c8b6093ff1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1d_nsclean_modified = [\n",
    "    stage2_nsclean_modified_dir + \"jw01335004001_03101_00002_nrs1_x1d.fits\",\n",
    "    stage2_nsclean_modified_dir + \"jw01335004001_03101_00002_nrs2_x1d.fits\",\n",
    "]\n",
    "\n",
    "# Wavelength region of interest\n",
    "wavelength_range = {\"nrs1\": [1.15, 1.25], \"nrs2\": [1.65, 1.75]}\n",
    "for original, cleaned in zip(x1d_nsclean_skipped, x1d_nsclean_modified):\n",
    "    plot_spectra(\n",
    "        [original, cleaned], scale_percent=4, wavelength_range=wavelength_range\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5072ecbe-6b80-4b84-a104-b5477afa0cc2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Notes:</b> \n",
    "* Even when masking the handful of snowballs we encountered, the spectra remain similar to those cleaned with the default mask.\n",
    "* The portion of the spectrum near 1.2um for NRS1 and 1.7um for NRS2, the excess flux due to 1/f noise is reduced.\n",
    "* There are several spikes in the difference between the cleaned and original spectra. These correspond to the scattered artifacts introduced by the cleaning process, above.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86daa01-29bd-4ce4-9a63-0091e0dbcf2b",
   "metadata": {},
   "source": [
    "## 9. Conclusion <a name=\"conclusion\"></a>\n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "The final plots below show the countrate images and the resulting 1D extracted spectra side-by-side to compare the different cleaning methods: the original (no NSClean applied), the cleaned countrate image (with the default pipeline mask), the cleaned countrate image (with an alternate pipeline mask), and finally, the cleaned countrate image (with the hand-modified mask).\n",
    "\n",
    "Please note that the results presented in this notebook may vary for different datasets (e.g., targets of different brightness, spatial extent, etc.). Users are encouraged to explore NSClean using different masking methods to determine the optimal results.\n",
    "\n",
    "The output from the cleaning algorithm is now ready for further processing.  The (*_cal.fits*) files produced by the above `Spec2Pipeline` run may be used as input to the `Spec3Pipeline`, for generating final combined spectral cubes and extracted spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ab935-6da2-45ef-8ada-1175d63a8272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not cleaned vs. cleaned (default mask) vs. cleaned (alternate mask) rate data\n",
    "original_rate_data = [\n",
    "    fits.open(mast_products_dir + rate_name)[1].data for rate_name in rate_names\n",
    "]\n",
    "cleaned_rate_default_data = [\n",
    "    fits.open(cleaned_default_mask)[1].data\n",
    "    for cleaned_default_mask in cleaned_default_masks\n",
    "]\n",
    "cleaned_rate_alternate_data = [\n",
    "    fits.open(cleaned_alternate_mask)[1].data\n",
    "    for cleaned_alternate_mask in cleaned_alternate_masks\n",
    "]\n",
    "cleaned_rate_modified_data = [\n",
    "    fits.open(cleaned_modified_mask)[1].data\n",
    "    for cleaned_modified_mask in cleaned_modified_masks\n",
    "]\n",
    "\n",
    "# For plotting visualization\n",
    "for data_list in [\n",
    "    original_rate_data,\n",
    "    cleaned_rate_default_data,\n",
    "    cleaned_rate_alternate_data,\n",
    "    cleaned_rate_modified_data,\n",
    "]:\n",
    "    for data in data_list:\n",
    "        data[np.isnan(data)] = 0\n",
    "\n",
    "# Original vs. cleaned data (with default mask)\n",
    "fig, axs = plt.subplots(2, 4, figsize=(25, 12))\n",
    "\n",
    "# Set y-axis titles and plot the data\n",
    "titles = [\n",
    "    \"Original Rate Data\",\n",
    "    \"Cleaned Rate Data (Default Mask)\",\n",
    "    \"Cleaned Rate Data (Alternate Mask)\",\n",
    "    \"Cleaned Rate Data (Hand-Modified Mask)\",\n",
    "]\n",
    "for i, (data_list, title) in enumerate(\n",
    "    zip(\n",
    "        [\n",
    "            original_rate_data,\n",
    "            cleaned_rate_default_data,\n",
    "            cleaned_rate_alternate_data,\n",
    "            cleaned_rate_modified_data,\n",
    "        ],\n",
    "        titles,\n",
    "    )\n",
    "):\n",
    "    for j, data in enumerate(data_list):\n",
    "        ax = axs[j, i]\n",
    "        ax.set_title(f'{title} \\n {\"NRS1\" if j == 0 else \"NRS2\"}', fontsize=12)\n",
    "        im = ax.imshow(data, origin=\"lower\", clim=(-1e-3, 1e-2))\n",
    "        fig.colorbar(im, ax=ax, pad=0.05, shrink=0.7, label=\"DN/s\")\n",
    "        ax.set_xlabel(\"Pixel Column\", fontsize=10)\n",
    "        ax.set_ylabel(\"Pixel Row\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8622f2-0b6d-41eb-b38e-ac09f60a9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Comparison\n",
    "\n",
    "# Wavelength region of interest\n",
    "wavelength_range = {\"nrs1\": [1.15, 1.25], \"nrs2\": [1.65, 1.75]}\n",
    "\n",
    "plot_spectra(\n",
    "    [\n",
    "        x1d_nsclean_skipped[0],\n",
    "        x1d_nsclean_default[0],\n",
    "        x1d_nsclean_alternate[0],\n",
    "        x1d_nsclean_modified[0],\n",
    "    ],\n",
    "    wavelength_range=wavelength_range,\n",
    "    scale_percent=4,\n",
    ")\n",
    "plot_spectra(\n",
    "    [\n",
    "        x1d_nsclean_skipped[1],\n",
    "        x1d_nsclean_default[1],\n",
    "        x1d_nsclean_alternate[1],\n",
    "        x1d_nsclean_modified[1],\n",
    "    ],\n",
    "    wavelength_range=wavelength_range,\n",
    "    scale_percent=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac02101-ef88-40a1-a557-19355e967466",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> Cleaning with the alternate mask still removes some of the wavelength-dependent variations but leaves residual background variation in NRS2. Also note the overall continuum level for the spectrum has changed, especially for NRS1. Again, this is because sigma-clipping, unlike the default method, only masks the bright outliers, rather than the entire science region. Consequently, some sky regions are included in the background model that gets subtracted from the data, which can result in changes to the continuum level. In this case, the original algorithm, which blocks the entire science region for each IFU slice (or the hand-modified method to exclude snowballs), is preferable to creating the mask via sigma-clipping.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
